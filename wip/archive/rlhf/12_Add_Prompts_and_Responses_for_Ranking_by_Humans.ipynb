{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add items for human feedback\n",
    "\n",
    "![Pipeline](img/generative_ai_pipeline_rlhf_plus.png)\n",
    "\n",
    "![RLHF](img/rlhf_summarization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=4059807744, available=2247741440, percent=44.6, used=1569533952, free=2090758144, active=1614114816, inactive=122601472, buffers=0, cached=399515648, shared=1220608, slab=130486272)\n",
      "*******************************************\n",
      "YOU ARE NOT USING THE CORRECT INSTANCE TYPE\n",
      "PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge \n",
      "*******************************************\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "notebook_memory = psutil.virtual_memory()\n",
    "print(notebook_memory)\n",
    "\n",
    "if notebook_memory.total < 32 * 1000 * 1000 * 1000:\n",
    "    print('*******************************************')    \n",
    "    print('YOU ARE NOT USING THE CORRECT INSTANCE TYPE')\n",
    "    print('PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge ')\n",
    "    print('*******************************************')\n",
    "else:\n",
    "    correct_instance_type=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Amazon Python SDK clients\n",
    "sagemaker = boto3.client(\"sagemaker\", region)\n",
    "a2i = boto3.client(\"sagemaker-a2i-runtime\")\n",
    "s3 = boto3.client(\"s3\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the `augmented_ai_flow_definition_arn` Created Previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r augmented_ai_flow_definition_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:079002598131:flow-definition/fd-ranking-baeb7ab3-ea6f-418c-b63b-2b646f15c80d\n"
     ]
    }
   ],
   "source": [
    "print(augmented_ai_flow_definition_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [\n",
    "    {\"prompt\": \"Antje:  Will you write another O'Reilly book with me, Chris?\\nChris:  Yes, let's start 3 months from now.\\nAntje:  OK.\\n\",\n",
    "     \"responses\": [\"Chris and Antje will write another O'Reilly book starting in 3 months.\", \"Antje will write the book by herself right now.\"]},\n",
    "    {\"prompt\": \"Shelbee:  The wine will arrive in 10 minutes.\\nChris:  Can you drink the wine?  I leave for the airport in 5 minutes.\\nShelbee:  OK, I will.\\n\", \n",
    "     \"responses\": [\"Chris drank the wine in 5 minutes.\", \"Shelbee drank the wine in 10 minutes.\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item: \"{'prompt': \"Antje:  Will you write another O'Reilly book with me, Chris?\\nChris:  Yes, let's start 3 months from now.\\nAntje:  OK.\\n\", 'responses': [\"Chris and Antje will write another O'Reilly book starting in 3 months.\", 'Antje will write the book by herself right now.']}\"\n",
      "*** ==> Starting human loop with name: 088017b6-3740-4059-b260-7d5b0446ed2f  \n",
      "\n",
      "Processing item: \"{'prompt': 'Shelbee:  The wine will arrive in 10 minutes.\\nChris:  Can you drink the wine?  I leave for the airport in 5 minutes.\\nShelbee:  OK, I will.\\n', 'responses': ['Chris drank the wine in 5 minutes.', 'Shelbee drank the wine in 10 minutes.']}\"\n",
      "*** ==> Starting human loop with name: db20ad98-5211-48c1-8fb0-a74872ccc3b2  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_loops_started = []\n",
    "\n",
    "for item in items:\n",
    "    print(f'Processing item: \"{item}\"')\n",
    "\n",
    "    humanLoopName = str(uuid.uuid4())\n",
    "    inputContent = {\"taskObject\": item}\n",
    "    start_loop_response = a2i.start_human_loop(\n",
    "        HumanLoopName=humanLoopName,\n",
    "        FlowDefinitionArn=augmented_ai_flow_definition_arn,\n",
    "        HumanLoopInput={\"InputContent\": json.dumps(inputContent)},\n",
    "    )\n",
    "\n",
    "    human_loops_started.append(humanLoopName)\n",
    "\n",
    "    print(f\"*** ==> Starting human loop with name: {humanLoopName}  \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'human_loops_started' (list)\n"
     ]
    }
   ],
   "source": [
    "%store human_loops_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Status of Human Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 088017b6-3740-4059-b260-7d5b0446ed2f\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-079002598131/ground-truth-star-rating-results/fd-ranking-baeb7ab3-ea6f-418c-b63b-2b646f15c80d/2023/04/21/21/05/37/088017b6-3740-4059-b260-7d5b0446ed2f/output.json'}\n",
      "\n",
      "HumanLoop Name: db20ad98-5211-48c1-8fb0-a74872ccc3b2\n",
      "HumanLoop Status: InProgress\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-079002598131/ground-truth-star-rating-results/fd-ranking-baeb7ab3-ea6f-418c-b63b-2b646f15c80d/2023/04/21/21/05/37/db20ad98-5211-48c1-8fb0-a74872ccc3b2/output.json'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f\"HumanLoop Name: {human_loop_name}\")\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print(\"\")\n",
    "\n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wait For Workers to Complete Their Human Loop Tasks\n",
    "\n",
    "Navigate to the link below and login with your email and password that you used when you set up the Private Workforce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r augmented_ai_workteam_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:079002598131:workteam/private-crowd/dsoaws\n"
     ]
    }
   ],
   "source": [
    "print(augmented_ai_workteam_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsoaws\n",
      "Navigate to the private worker portal and complete the human loop.\n",
      "Make sure you have invited yourself to the workteam and received the signup email.\n",
      "Note:  Check your spam filter if you have not received the email.\n",
      "\n",
      "https://d0xvtcio9i.labeling.us-east-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteam_name = augmented_ai_workteam_arn[augmented_ai_workteam_arn.rfind(\"/\") + 1 :]\n",
    "print(workteam_name)\n",
    "print(\"Navigate to the private worker portal and complete the human loop.\")\n",
    "print(\"Make sure you have invited yourself to the workteam and received the signup email.\")\n",
    "print(\"Note:  Check your spam filter if you have not received the email.\")\n",
    "print(\"\")\n",
    "print(\"https://\" + sagemaker.describe_workteam(WorkteamName=workteam_name)[\"Workteam\"][\"SubDomain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _YOU MUST LABEL THE DATA BY CLICKING THE LINK ABOVE BEFORE CONTINUING!!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Labeling\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-start-working.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Label\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-select-label.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loop is Completed\n",
    "\n",
    "<img src=\"img/augmented-comprehend-custom-finished-task.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the Human Loops are Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsoaws\n",
      "Navigate to the private worker portal and complete the human loop.\n",
      "Make sure you have invited yourself to the workteam and received the signup email.\n",
      "Note:  Check your spam filter if you have not received the email.\n",
      "\n",
      "https://d0xvtcio9i.labeling.us-east-1.sagemaker.aws\n"
     ]
    }
   ],
   "source": [
    "workteam_name = augmented_ai_workteam_arn[augmented_ai_workteam_arn.rfind(\"/\") + 1 :]\n",
    "print(workteam_name)\n",
    "print(\"Navigate to the private worker portal and complete the human loop.\")\n",
    "print(\"Make sure you have invited yourself to the workteam and received the signup email.\")\n",
    "print(\"Note:  Check your spam filter if you have not received the email.\")\n",
    "print(\"\")\n",
    "print(\"https://\" + sagemaker.describe_workteam(WorkteamName=workteam_name)[\"Workteam\"][\"SubDomain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HumanLoop Name: 088017b6-3740-4059-b260-7d5b0446ed2f\n",
      "HumanLoop Status: Completed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-079002598131/ground-truth-star-rating-results/fd-ranking-baeb7ab3-ea6f-418c-b63b-2b646f15c80d/2023/04/21/21/05/37/088017b6-3740-4059-b260-7d5b0446ed2f/output.json'}\n",
      "\n",
      "Completed!\n",
      "\n",
      "HumanLoop Name: db20ad98-5211-48c1-8fb0-a74872ccc3b2\n",
      "HumanLoop Status: Completed\n",
      "HumanLoop Output Destination: {'OutputS3Uri': 's3://sagemaker-us-east-1-079002598131/ground-truth-star-rating-results/fd-ranking-baeb7ab3-ea6f-418c-b63b-2b646f15c80d/2023/04/21/21/05/37/db20ad98-5211-48c1-8fb0-a74872ccc3b2/output.json'}\n",
      "\n",
      "Completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "completed_human_loops = []\n",
    "for human_loop_name in human_loops_started:\n",
    "    resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    print(f\"HumanLoop Name: {human_loop_name}\")\n",
    "    print(f'HumanLoop Status: {resp[\"HumanLoopStatus\"]}')\n",
    "    print(f'HumanLoop Output Destination: {resp[\"HumanLoopOutput\"]}')\n",
    "    print(\"\")\n",
    "    while resp[\"HumanLoopStatus\"] != \"Completed\":\n",
    "        print(f\"Waiting for HumanLoop to complete.\")\n",
    "        time.sleep(10)\n",
    "        resp = a2i.describe_human_loop(HumanLoopName=human_loop_name)\n",
    "    if resp[\"HumanLoopStatus\"] == \"Completed\":\n",
    "        completed_human_loops.append(resp)\n",
    "        print(f\"Completed!\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# View Human Labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the work is complete, Amazon GroundTruth stores the results in the specified S3 bucket and sends a Cloudwatch Event.  Here is a sample item labeled with GroundTruth in `jsonlines` format:\n",
    "```\n",
    "{\n",
    " \"inputContent\": {\n",
    "     \"taskObject\": {\n",
    "         \"prompt\": \"Antje:  Will you write another O'Reilly book with me, Chris?\\nChris:  Yes, let's start 3 months from now.\\nAntje:  OK.\\n\",\n",
    "            \"responses\": [\n",
    "                \"Chris and Antje will write another O'Reilly book starting in 3 months.\", \n",
    "                \"Antje will write the book by herself right now.\"\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    \"humanAnswers\": [{\n",
    "        \"answerContent\": {\n",
    "            \"ranking_1\": \"1\", # ranking for 1st response (1 is High)\n",
    "            \"ranking_2\": \"2\"  # ranking for 2nd response (2 is Low)\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare human-labeled data for RL/PPO training\n",
    "Retrieve from GrountTruth and convert to a binary reward (0 or 1) for all rankings as shown below.\n",
    "\n",
    "TODO:  Convert this into markdown table\n",
    "\n",
    "From this:\n",
    "```\n",
    "prompt                     response       ranking\n",
    "\n",
    "Antje:  Will you write...    Chris and Antje...   2   # High\n",
    "Antje:  Will you write...    Antje will....       1   # Low\n",
    "```\n",
    "\n",
    "To this:\n",
    "```\n",
    "prompt                     response       ranking\n",
    "\n",
    "Antje:  Will you write...    Chris and Antje...   0   # High\n",
    "Antje:  Will you write...    Antje will....       1   # Low\n",
    "```\n",
    "\n",
    "To this:\n",
    "```\n",
    "prompt                     response                                               reward\n",
    "\n",
    "Antje:  Will you write...    [\"Chris and Antje...\", \"Antje will...\"]     [1,0] # 0-index is rewarded\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# _Note:  If nothing is showing up below, you need to return to finish the previous notebook by labeling the data in Ground Truth!!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "human_feedback_items = []\n",
    "\n",
    "for resp in completed_human_loops:\n",
    "    human_feedback_s3_uri = resp[\"HumanLoopOutput\"][\"OutputS3Uri\"]\n",
    "    split_string = re.split(\"s3://\" + bucket + \"/\", resp[\"HumanLoopOutput\"][\"OutputS3Uri\"])\n",
    "    key = split_string[1]\n",
    "    \n",
    "    response = s3.get_object(Bucket=bucket, Key=key)\n",
    "    content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "    json_output = json.loads(content)\n",
    "\n",
    "    prompt = json_output[\"inputContent\"]['taskObject']['prompt']\n",
    "    responses = json_output[\"inputContent\"]['taskObject']['responses']\n",
    "    response_1_ranking = json_output[\"humanAnswers\"][0][\"answerContent\"]['response_1_ranking']\n",
    "    response_2_ranking = json_output[\"humanAnswers\"][0][\"answerContent\"]['response_2_ranking']\n",
    "    \n",
    "    human_feedback_item_1 = (prompt, responses[0], response_1_ranking)\n",
    "    human_feedback_items.append(human_feedback_item_1)\n",
    "    human_feedback_item_2 = (prompt, responses[1], response_2_ranking)\n",
    "    human_feedback_items.append(human_feedback_item_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antje:  Will you write another O'Reilly book w...</td>\n",
       "      <td>Chris and Antje will write another O'Reilly bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antje:  Will you write another O'Reilly book w...</td>\n",
       "      <td>Antje will write the book by herself right now.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shelbee:  The wine will arrive in 10 minutes.\\...</td>\n",
       "      <td>Chris drank the wine in 5 minutes.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shelbee:  The wine will arrive in 10 minutes.\\...</td>\n",
       "      <td>Shelbee drank the wine in 10 minutes.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Antje:  Will you write another O'Reilly book w...   \n",
       "1  Antje:  Will you write another O'Reilly book w...   \n",
       "2  Shelbee:  The wine will arrive in 10 minutes.\\...   \n",
       "3  Shelbee:  The wine will arrive in 10 minutes.\\...   \n",
       "\n",
       "                                            response ranking  \n",
       "0  Chris and Antje will write another O'Reilly bo...       1  \n",
       "1    Antje will write the book by herself right now.       2  \n",
       "2                 Chris drank the wine in 5 minutes.       2  \n",
       "3              Shelbee drank the wine in 10 minutes.       1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items = pd.DataFrame(human_feedback_items, columns=['prompt', 'response', 'ranking'])\n",
    "df_human_feedback_items.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert ranking into 0 or 1 reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>ranking</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antje:  Will you write another O'Reilly book w...</td>\n",
       "      <td>Chris and Antje will write another O'Reilly bo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antje:  Will you write another O'Reilly book w...</td>\n",
       "      <td>Antje will write the book by herself right now.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shelbee:  The wine will arrive in 10 minutes.\\...</td>\n",
       "      <td>Chris drank the wine in 5 minutes.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shelbee:  The wine will arrive in 10 minutes.\\...</td>\n",
       "      <td>Shelbee drank the wine in 10 minutes.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Antje:  Will you write another O'Reilly book w...   \n",
       "1  Antje:  Will you write another O'Reilly book w...   \n",
       "2  Shelbee:  The wine will arrive in 10 minutes.\\...   \n",
       "3  Shelbee:  The wine will arrive in 10 minutes.\\...   \n",
       "\n",
       "                                            response ranking reward  \n",
       "0  Chris and Antje will write another O'Reilly bo...       1      1  \n",
       "1    Antje will write the book by herself right now.       2      0  \n",
       "2                 Chris drank the wine in 5 minutes.       2      0  \n",
       "3              Shelbee drank the wine in 10 minutes.       1      1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rankings = 2\n",
    "df_human_feedback_items['response'] = df_human_feedback_items['response'].apply(lambda response: str(response))\n",
    "df_human_feedback_items['reward'] = df_human_feedback_items['ranking'].apply(lambda ranking: str(abs(int(ranking) - num_rankings)))\n",
    "df_human_feedback_items.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antje:  Will you write another O'Reilly book w...</td>\n",
       "      <td>Chris and Antje will write another O'Reilly bo...</td>\n",
       "      <td>1,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shelbee:  The wine will arrive in 10 minutes.\\...</td>\n",
       "      <td>Chris drank the wine in 5 minutes.,Shelbee dra...</td>\n",
       "      <td>0,1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Antje:  Will you write another O'Reilly book w...   \n",
       "1  Shelbee:  The wine will arrive in 10 minutes.\\...   \n",
       "\n",
       "                                            response reward  \n",
       "0  Chris and Antje will write another O'Reilly bo...    1,0  \n",
       "1  Chris drank the wine in 5 minutes.,Shelbee dra...    0,1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items_grouped_by_prompt = df_human_feedback_items.groupby('prompt', as_index=False).agg({'prompt' : 'first', 'response' : ','.join, 'reward' : ','.join})\n",
    "df_human_feedback_items_grouped_by_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antje:  Will you write another O'Reilly book w...</td>\n",
       "      <td>[Chris and Antje will write another O'Reilly b...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shelbee:  The wine will arrive in 10 minutes.\\...</td>\n",
       "      <td>[Chris drank the wine in 5 minutes., Shelbee d...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Antje:  Will you write another O'Reilly book w...   \n",
       "1  Shelbee:  The wine will arrive in 10 minutes.\\...   \n",
       "\n",
       "                                            response  reward  \n",
       "0  [Chris and Antje will write another O'Reilly b...  [1, 0]  \n",
       "1  [Chris drank the wine in 5 minutes., Shelbee d...  [0, 1]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_feedback_items_grouped_by_prompt['response'] = df_human_feedback_items_grouped_by_prompt['response'].apply(lambda response: [s for s in response.split(',')])\n",
    "df_human_feedback_items_grouped_by_prompt['reward'] = df_human_feedback_items_grouped_by_prompt['reward'].apply(lambda reward: [int(s) for s in reward.split(',')])\n",
    "df_human_feedback_items_grouped_by_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'reward'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create Dataset objects (Arrow PyTables) from Pandas dataframes\n",
    "human_feedback_dataset = Dataset.from_pandas(df_human_feedback_items_grouped_by_prompt)\n",
    "human_feedback_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'human_feedback_dataset' (Dataset)\n"
     ]
    }
   ],
   "source": [
    "%store human_feedback_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _YOU MUST LABEL THE DATA BY CLICKING THE LINK ABOVE BEFORE CONTINUING!!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%html\n",
    "\n",
    "# <p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "# <button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "\n",
    "# <script>\n",
    "# try {\n",
    "#     els = document.getElementsByClassName(\"sm-command-button\");\n",
    "#     els[0].click();\n",
    "# }\n",
    "# catch(err) {\n",
    "#     // NoOp\n",
    "# }\n",
    "# </script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
